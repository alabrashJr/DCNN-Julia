{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Abdulrahman Alabrash \n",
    "\n",
    "https://github.com/alabrashJr/DCNN-Julia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Widgets ───────────── v0.6.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m ZipFile ───────────── v0.8.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Images ────────────── v0.17.3\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m PyCall ────────────── v1.91.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m IJulia ────────────── v1.18.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Plots ─────────────── v0.24.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m FileIO ────────────── v1.0.6\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m WebSockets ────────── v1.5.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Ratios ────────────── v0.3.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m MacroTools ────────── v0.5.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Compat ────────────── v2.1.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m DocStringExtensions ─ v0.7.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CUDAapi ───────────── v0.6.3\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m TranscodingStreams ── v0.9.3\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m PlotUtils ─────────── v0.5.7\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Tokenize ──────────── v0.5.3\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m LibCURL ───────────── v0.5.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m SoftGlobalScope ───── v1.0.10\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Tables ────────────── v0.1.18\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Mux ───────────────── v0.7.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m HTTP ──────────────── v0.8.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m GR ────────────────── v0.39.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Crayons ───────────── v4.0.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CSTParser ─────────── v0.5.2\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [5789e2e9]\u001b[39m\u001b[93m ↑ FileIO v1.0.5 ⇒ v1.0.6\u001b[39m\n",
      " \u001b[90m [7073ff75]\u001b[39m\u001b[93m ↑ IJulia v1.17.0 ⇒ v1.18.0\u001b[39m\n",
      " \u001b[90m [916415d5]\u001b[39m\u001b[93m ↑ Images v0.17.2 ⇒ v0.17.3\u001b[39m\n",
      " \u001b[90m [91a5bcdd]\u001b[39m\u001b[93m ↑ Plots v0.23.1 ⇒ v0.24.0\u001b[39m\n",
      " \u001b[90m [438e738f]\u001b[39m\u001b[93m ↑ PyCall v1.90.0 ⇒ v1.91.1\u001b[39m\n",
      " \u001b[90m [a5390f91]\u001b[39m\u001b[93m ↑ ZipFile v0.8.0 ⇒ v0.8.1\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      " \u001b[90m [00ebfdb7]\u001b[39m\u001b[92m + CSTParser v0.5.2\u001b[39m\n",
      " \u001b[90m [3895d2a7]\u001b[39m\u001b[93m ↑ CUDAapi v0.6.0 ⇒ v0.6.3\u001b[39m\n",
      " \u001b[90m [34da2185]\u001b[39m\u001b[93m ↑ Compat v2.0.0 ⇒ v2.1.0\u001b[39m\n",
      " \u001b[90m [a8cc5b0e]\u001b[39m\u001b[93m ↑ Crayons v1.0.0 ⇒ v4.0.0\u001b[39m\n",
      " \u001b[90m [ffbed154]\u001b[39m\u001b[93m ↑ DocStringExtensions v0.6.0 ⇒ v0.7.0\u001b[39m\n",
      " \u001b[90m [5789e2e9]\u001b[39m\u001b[93m ↑ FileIO v1.0.5 ⇒ v1.0.6\u001b[39m\n",
      " \u001b[90m [28b8d3ca]\u001b[39m\u001b[93m ↑ GR v0.38.1 ⇒ v0.39.0\u001b[39m\n",
      " \u001b[90m [cd3eb016]\u001b[39m\u001b[93m ↑ HTTP v0.7.1 ⇒ v0.8.0\u001b[39m\n",
      " \u001b[90m [7073ff75]\u001b[39m\u001b[93m ↑ IJulia v1.17.0 ⇒ v1.18.0\u001b[39m\n",
      " \u001b[90m [916415d5]\u001b[39m\u001b[93m ↑ Images v0.17.2 ⇒ v0.17.3\u001b[39m\n",
      " \u001b[90m [b27032c2]\u001b[39m\u001b[93m ↑ LibCURL v0.4.1 ⇒ v0.5.0\u001b[39m\n",
      " \u001b[90m [1914dd2f]\u001b[39m\u001b[93m ↑ MacroTools v0.4.5 ⇒ v0.5.0\u001b[39m\n",
      " \u001b[90m [a975b10e]\u001b[39m\u001b[93m ↑ Mux v0.6.0 ⇒ v0.7.0\u001b[39m\n",
      " \u001b[90m [995b91a9]\u001b[39m\u001b[93m ↑ PlotUtils v0.5.5 ⇒ v0.5.7\u001b[39m\n",
      " \u001b[90m [91a5bcdd]\u001b[39m\u001b[93m ↑ Plots v0.23.1 ⇒ v0.24.0\u001b[39m\n",
      " \u001b[90m [438e738f]\u001b[39m\u001b[93m ↑ PyCall v1.90.0 ⇒ v1.91.1\u001b[39m\n",
      " \u001b[90m [c84ed2f1]\u001b[39m\u001b[93m ↑ Ratios v0.3.0 ⇒ v0.3.1\u001b[39m\n",
      " \u001b[90m [b9d75638]\u001b[39m\u001b[91m - SIUnits v0.1.0\u001b[39m\n",
      " \u001b[90m [b85f4697]\u001b[39m\u001b[93m ↑ SoftGlobalScope v1.0.9 ⇒ v1.0.10\u001b[39m\n",
      " \u001b[90m [bd369af6]\u001b[39m\u001b[93m ↑ Tables v0.1.17 ⇒ v0.1.18\u001b[39m\n",
      " \u001b[90m [9b435220]\u001b[39m\u001b[91m - TexExtensions v0.1.0\u001b[39m\n",
      " \u001b[90m [0796e94c]\u001b[39m\u001b[92m + Tokenize v0.5.3\u001b[39m\n",
      " \u001b[90m [3bb67fe8]\u001b[39m\u001b[93m ↑ TranscodingStreams v0.9.0 ⇒ v0.9.3\u001b[39m\n",
      " \u001b[90m [104b5d7c]\u001b[39m\u001b[93m ↑ WebSockets v1.3.1 ⇒ v1.5.2\u001b[39m\n",
      " \u001b[90m [cc8bc4a8]\u001b[39m\u001b[93m ↑ Widgets v0.5.0 ⇒ v0.6.1\u001b[39m\n",
      " \u001b[90m [a5390f91]\u001b[39m\u001b[93m ↑ ZipFile v0.8.0 ⇒ v0.8.1\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m ZipFile → `~/.julia/packages/ZipFile/YHTbb/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PyCall ─→ `~/.julia/packages/PyCall/a5Jd3/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m IJulia ─→ `~/.julia/packages/IJulia/9ajf8/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m GR ─────→ `~/.julia/packages/GR/Q8slp/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Plots ──→ `~/.julia/packages/Plots/47Tik/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m LibCURL → `~/.julia/packages/LibCURL/khRkY/deps/build.log`\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m AutoHashEquals ─ v0.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m DataDeps ─────── v0.6.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Embeddings ───── v0.3.0\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [c5bfea45]\u001b[39m\u001b[92m + Embeddings v0.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      " \u001b[90m [15f4f7f2]\u001b[39m\u001b[92m + AutoHashEquals v0.2.0\u001b[39m\n",
      " \u001b[90m [124859b0]\u001b[39m\u001b[92m + DataDeps v0.6.2\u001b[39m\n",
      " \u001b[90m [c5bfea45]\u001b[39m\u001b[92m + Embeddings v0.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m DataFrames ──────── v0.17.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m DataStreams ─────── v0.4.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m WeakRefStrings ──── v0.5.8\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CategoricalArrays ─ v0.5.2\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [a93c6f00]\u001b[39m\u001b[92m + DataFrames v0.17.1\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      " \u001b[90m [324d7699]\u001b[39m\u001b[92m + CategoricalArrays v0.5.2\u001b[39m\n",
      " \u001b[90m [a93c6f00]\u001b[39m\u001b[92m + DataFrames v0.17.1\u001b[39m\n",
      " \u001b[90m [9a8bc11e]\u001b[39m\u001b[92m + DataStreams v0.4.1\u001b[39m\n",
      " \u001b[90m [ea10d353]\u001b[39m\u001b[92m + WeakRefStrings v0.5.8\u001b[39m\n",
      " \u001b[90m [9fa8497b]\u001b[39m\u001b[92m + Future \u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [864edb3b]\u001b[39m\u001b[92m + DataStructures v0.15.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [37e2e46d]\u001b[39m\u001b[92m + LinearAlgebra \u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling DataFrames [a93c6f00-e57d-5684-b7b6-d8193f3e46c0]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Warning: Module Compat with build ID 539816466986 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Warning: Module Compat with build ID 539816466986 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling DataStreams [9a8bc11e-79be-5b39-94d7-1ccc349a1a85]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Info: Recompiling stale cache file /home/ec2-user/.julia/compiled/v1.1/CodecZlib/1TI30.ji for CodecZlib [944b1d66-785c-5afd-91f1-9de20f533193]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /home/ec2-user/.julia/compiled/v1.1/Tables/Z804B.ji for Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /home/ec2-user/.julia/compiled/v1.1/FileIO/6iKRU.ji for FileIO [5789e2e9-d7fb-5bc7-8068-2c6fae9b9549]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Precompiling Embeddings [c5bfea45-b7f1-5224-a596-15500f5db411]\n",
      "└ @ Base loading.jl:1186\n"
     ]
    }
   ],
   "source": [
    "using Pkg;Pkg.update(); for p in (\"Embeddings\",\"DataFrames\",\"DataStructures\",\"DataFrames\",\"FileIO\",\"LinearAlgebra\",\"Knet\",\"FileIO\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "using DataStructures,DataFrames,FileIO,Embeddings,LinearAlgebra,DataFrames\n",
    "#using Knet: Knet, conv4, pool, mat, KnetArray, nll, zeroone, progress, sgd, param, param0, dropout, relu, Data,minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from saved file \n",
    "load(\"TREC_sib.jld2\",\"datas\")-> returns revs, W, W2, word_idx_map, vocab\n",
    "* revs Dict{String,Any} with 5 entries:y,num_words,tree,text,split\n",
    "    * y-> label of the questions 1-5 \n",
    "    * num_words-> length of questions \n",
    "    * tree -> 46-element Array{Array,1}, each array contains data_sibling(5)+data_tree(5) =10\n",
    "    * text -> the question text \n",
    "    * split -> type of tuple (training, test , div)\n",
    "\n",
    "\n",
    "\n",
    "* W wordembedding generated by google2vec, size(10098×300)\n",
    "* W2 word embedding generated by -0.25 , 0.25 size(10098×300)\n",
    "* word_idx_map Dict{Any,Any} with 10097 entries , unique word id dictionary \n",
    "* vocab DefaultDict{Any,Any,Int64} with 10097 entries, vocab and reptation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"abbreviation\", \"entity\", \"description\", \"location\" ,\"numeric\",\" \"]\n",
    "revs, W, W2, word_idx_map, vocab=load(\"Data/TREC_sib.jld2\",\"datas\"); \n",
    "word_idx_map[\"ROOT\"] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(P(KnetArray{Float32,2}(10097,300)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change W2 with prof's method \n",
    "struct Embed; w; end\n",
    "Embed(vocabsize::Int,embedsize::Int) = Embed(param(embedsize,vocabsize))\n",
    "(e::Embed)(x) = e.w[:,x]\n",
    "W2=Embed(300,length(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_text_mat (generic function with 2 methods)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforms sentence into a list of indices. Pad with zeroes.\n",
    "function get_text_mat(t,word_idx_map;max_l=56,filter_h=5)\n",
    "    #t the text of question\n",
    "    x=[] # output matrix\n",
    "    pad=filter_h -1 # padding number\n",
    "    for i in collect(1:pad);push!(x,0);end #adding padding \n",
    "    words=split(t)\n",
    "    #extract the unique id of words in the question text and adding it to the matrix \n",
    "    for w in words\n",
    "        if w in keys(word_idx_map);push!(x,word_idx_map[w])\n",
    "        else; @show w ;end\n",
    "    end    \n",
    "\n",
    "    while length(x)<max_l+2*pad    # accomplish 64 +1 size by adding zeros till finish \n",
    "            push!(x,0)\n",
    "    end\n",
    "    \n",
    "    return  x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_tree_rep (generic function with 1 method)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforms sentence into a list of indices. Pad with zeroes. \n",
    "function get_tree_rep(r,word_idx_map)\n",
    "# question \n",
    "#@show t=r[\"tree\"] #the tree of question\n",
    "    each_sent=deepcopy(r)# output matrix\n",
    "    for (j, each_word) in enumerate(each_sent[1:end-1])\n",
    "        #@show (j, each_word)\n",
    "            for (l, each_field) in enumerate(each_word)\n",
    "           # @show (l, each_field)\n",
    "                if each_field in keys( word_idx_map)\n",
    "                #@show j,l ;\n",
    "                    each_sent[j]=Array{Any,1}(each_sent[j])\n",
    "                     each_sent[j][l] = word_idx_map[each_field]\n",
    "                elseif each_field == 0\n",
    "                    continue\n",
    "                else\n",
    "                    @show each_field\n",
    "                end\n",
    "            end\n",
    "    end       \n",
    "    return each_sent;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran = 4461\n",
      "What U.S. state boasts Leif Ericson Park ?\t8\n",
      "Any[0 0 0 0 6965 4384 9578 5068 288 9386 8878 1557 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "What=6965\n",
      "U.S.=4384\n",
      "state=9578\n",
      "boasts=5068\n",
      "Leif=288\n",
      "Ericson=9386\n",
      "Park=8878\n",
      "?=1557\n"
     ]
    }
   ],
   "source": [
    "ran=rand(1:length(revs));@show ran\n",
    "print(revs[ran][\"text\"]); println(\"\\t\",length(split(revs[ran][\"text\"])))\n",
    "println(permutedims(get_text_mat(revs[ran][\"text\"],word_idx_map;max_l=56) ))\n",
    "for i in split(revs[ran][\"text\"]) ;println(i,\"=\",word_idx_map[i]) ;end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"ROOT\", \"ROOT\", \"ROOT\", \"did\", \"develop\", \"did\", \"develop\", \"How\", \"*START*\", \"ROOT\"]\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: get_tree_rep not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: get_tree_rep not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[16]:4"
     ]
    }
   ],
   "source": [
    "ran=1#rand(1:length(revs))\n",
    "tree_ind=1\n",
    "println(revs[ran][\"tree\"][tree_ind])\n",
    "println(permutedims(get_tree_rep(revs[ran][\"tree\"],word_idx_map))[tree_ind])\n",
    "for i in revs[ran][\"tree\"][tree_ind] ;println(i,\"=\",word_idx_map[i]) ;end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_dev_test(revs)\n",
    "    s1,s2,s3=[],[],[]\n",
    "    t1,t2,t3=[],[],[]\n",
    "    for rev in revs\n",
    "    sent =get_text_mat(rev[\"text\"], word_idx_map)   \n",
    "    push!(sent,rev[\"y\"])\n",
    "    sent_tensor = get_tree_rep(rev[\"tree\"], word_idx_map)\n",
    "        \n",
    "    if rev[\"split\"]==1\n",
    "            push!(s1,Array{Int}(sent))\n",
    "            push!(t1,sent_tensor)\n",
    "    elseif rev[\"split\"]==2\n",
    "            push!(s2,Array{Int}(sent))\n",
    "            push!(t2,sent_tensor)\n",
    "    elseif rev[\"split\"]==3\n",
    "            push!(s3,Array{Int}(sent))\n",
    "            push!(t3,sent_tensor)\n",
    "    end\n",
    "end\n",
    "\n",
    "    train = hcat([f1 for f1 in s1]...)\n",
    "    test =hcat([f1 for f1 in s2]...)\n",
    "    dev = hcat([f1 for f1 in s3]...)\n",
    "    train_tensor = t1\n",
    "    test_tensor = t2\n",
    "    dev_tensor = t3\n",
    "    return (train,test,dev),(train_tensor,test_tensor,dev_tensor)\n",
    "end\n",
    "dataset,datasetTensor=train_dev_test(revs);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset[1] --> train 65×5451 } text data\n",
    "dataset[2]----> test 65×501  }\n",
    "dataset[3] ----> dev 0x0     }\n",
    "\n",
    "datasetTensor[1] ---> train_tensor 5451(46(10)))\n",
    "datasetTensor[2] ---> test_tensor 501(46(10)))\n",
    "datasetTensor[3] --->dev_tensor 0(0(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getSen (generic function with 1 method)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getSen(vector)\n",
    "#labels=[\"abbreviation\",\"numeric\",  \"description\", \"human\",\"location\" ,\"entity\"]\n",
    "t=Array{Int}(vector)\n",
    "println(permutedims(t))\n",
    "for i in t\n",
    "    if i==1557;print(\"?\\n y =\",t[end]+1 );break;end\n",
    "    if i==0;continue;end\n",
    "    for (key,value) in word_idx_map\n",
    "        if value==i; print(key,\" \");end\n",
    "    end\n",
    "end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 6965 1189 9009 9078 4689 9231 4560 9231 1241 1557 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]\n",
      "What is the largest county in size in Massachusetts ?\n",
      " y =5"
     ]
    }
   ],
   "source": [
    "#try on some vectors \n",
    "ran=rand(1:size(dataset[1],2))\n",
    "getSen(dataset[1][:,ran])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[dataset[1][:,x][end] for x in 1:size(dataset[1],2)];\n",
    "y_test=[dataset[2][:,x][end] for x in 1:size(dataset[2],2)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data{Tuple{Array{Int64,2},Array{Int64,1}}}([0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], [1 5 … 1 2], 160, 501, false, 342, 1:501, false, (64, 501), (501,), Array{Int64,2}, Array{Int64,1})"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrn=minibatch(dataset[1][1:end-1,:],y_train,160,shuffle=true) # 5451/170\n",
    "dtst=minibatch(dataset[2][1:end-1,:],y_test,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"64×160 Array{Int64,2}\", \"160-element Array{Int64,1}\")"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.(Iterators.first(dtrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Redefine dense layer (See mlp.ipynb):\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "(c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For running experiments\n",
    "filter_hs=[3,4,5], windows size ? \n",
    "hidden_units=[100,2] #which meaning ...... how many conv layers \n",
    "dropout_rate=[0.5] #where in which layer ? conv or dense\n",
    "shuffle_batch=True, \n",
    "n_epochs=20, \n",
    "batch_size=170, \n",
    "lr_decay = 0.95, lr\n",
    "conv_non_linear=\"relu\"\n",
    "\n",
    "function trainresults(file,model; o...)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        takeevery(n,itr) = (x for (i,x) in enumerate(itr) if i % n == 1)\n",
    "        r = ((model(dtrn), model(dtst), zeroone(model,dtrn), zeroone(model,dtst))\n",
    "             for x in takeevery(length(dtrn), progress(sgd(model,repeat(dtrn,100)))))\n",
    "        r = reshape(collect(Float32,flatten(r)),(4,:))\n",
    "        Knet.save(file,\"results\",r)\n",
    "        Knet.gc() # To save gpu memory\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        r = Knet.load(file,\"results\")\n",
    "    end\n",
    "    println(minimum(r,dims=2))\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lenet =   Chain(Conv(5,5,1,20), \n",
    "                Conv(5,5,20,50), \n",
    "                Dense(800,500,pdrop=0.3), \n",
    "                Dense(500,10,identity,pdrop=0.3))\n",
    "summary.(l.w for l in lenet.layers)\n",
    "cnn = trainresults(\"cnn113.jld2\", lenet);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
